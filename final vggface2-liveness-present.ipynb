{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from numpy import asarray\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "import pickle\n",
    "import cv2\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.svm import LinearSVC\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1223 11:52:26.768497  1776 deprecation_wrapper.py:119] From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1223 11:52:27.520138  1776 deprecation.py:323] From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1223 11:52:29.069718  1776 deprecation_wrapper.py:119] From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "liveness_model = load_model(\"liveness.model\")\n",
    "liveness_le = pickle.loads(open(\"le.pickle\", \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from align import AlignDlib\n",
    "alignment = AlignDlib('models/landmarks.dat')\n",
    "def align_image(img):\n",
    "    return alignment.align(224, img, alignment.getLargestFaceBoundingBox(img), \n",
    "                           landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(face):\n",
    "    face = [face]\n",
    "    samples = asarray(face,'float32')\n",
    "    samples = preprocess_input(samples, version=2)  \n",
    "    interpreter = tf.lite.Interpreter(model_path=\"sparse_mnist.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    input_data = np.array(samples, dtype=np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    yhat = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(embedded,targets):\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(targets)\n",
    "    # Numerical encoding of identities\n",
    "    y = encoder.transform(targets)\n",
    "    \n",
    "    embedded = np.array(embedded)\n",
    "    print(embedded)\n",
    "    \n",
    "    # 50 train examples of 10 identities (5 examples each)\n",
    "    X_train = embedded\n",
    "    # 50 test examples of 10 identities (5 examples each)\n",
    "\n",
    "    y_train = y\n",
    "    \n",
    "    svc = LinearSVC()\n",
    "#     SVC(kernel='linear', probability=True)\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    model_dump ={\n",
    "    \"classifier\" : svc,\n",
    "    \"embeddings\" : embedded, \n",
    "    \"targets\" : targets\n",
    "    } \n",
    "    with open('model_livenes.pkl', 'wb') as config_dictionary_file:\n",
    "          pickle.dump(model_dump, config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainfirst(embedded,targets):\n",
    "    \n",
    "    print(embedded)\n",
    "    clf = svm.OneClassSVM(kernel=\"rbf\", gamma=0.000001)\n",
    "    clf.fit(embedded)\n",
    "\n",
    "\n",
    "    model_dump ={\n",
    "    \"classifier\" : clf,\n",
    "    \"embeddings\" : embedded, \n",
    "    \"targets\" : targets\n",
    "    } \n",
    "    with open('model_livenes.pkl', 'wb') as config_dictionary_file:\n",
    "          pickle.dump(model_dump, config_dictionary_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## without augmentation\n",
    "def webcapture():\n",
    "    webcam = cv2.VideoCapture(1)\n",
    "    i=0\n",
    "    PADDING = 25\n",
    "    embedding = []\n",
    "    \n",
    "    while True:\n",
    "        ret, img = webcam.read()\n",
    "        i =i+1\n",
    "        if i > 10:\n",
    "            frame = img\n",
    "            try:\n",
    "                faces = align_image(img)\n",
    "            except:\n",
    "                print(\"please look at camera side\")\n",
    "            try:\n",
    "    #             print(len(faces))\n",
    "                cv2.imshow(\"Frame\", frame)\n",
    "                cv2.imshow(\"Frame1\", faces)\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "                # if the `q` key was pressed, break from the loop\n",
    "                if key == ord(\"q\"):\n",
    "                    break\n",
    "    #             print(len(faces))\n",
    "                if (len(faces) != 0): \n",
    "                    face = cv2.resize(faces, (32, 32))\n",
    "                    face = face.astype(\"float\") / 255.0\n",
    "                    face = img_to_array(face)\n",
    "                    face = np.expand_dims(face, axis=0)\n",
    "                    preds = liveness_model.predict(face)[0]\n",
    "                    j = np.argmax(preds)\n",
    "                    label = liveness_le.classes_[j]\n",
    "                    print(label,preds[j])\n",
    "                    if label == \"real\" and preds[j] > 0.85:\n",
    "                        webcam.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "                        embedding.append(get_embedding(faces))\n",
    "                        return embedding\n",
    "                    else:\n",
    "                        print(\"fake face\")\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_face():\n",
    "    embeddings = []\n",
    "    for i in range(0,10):\n",
    "        print(f\"{i+1} capturing\")\n",
    "        face = webcapture()\n",
    "        embeddings.append(face)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def predictfisrt():\n",
    "    old_model = pickle.load(open(\"model_livenes.pkl\", 'rb'))\n",
    "    clfmodel = old_model[\"classifier\"]\n",
    "    target = old_model[\"targets\"]\n",
    "    embeddings = old_model[\"embeddings\"]\n",
    "    target = np.unique(target)\n",
    "    embedding = webcapture()\n",
    "    avg = 0\n",
    "    for i in embeddings:\n",
    "        avg += cosine_similarity(embedding[0], [i])\n",
    "    avg = avg/10\n",
    "    print(\"avg\",avg)\n",
    "    if clfmodel.decision_function(embedding[0]) > -0.004 or avg > 0.60 :\n",
    "        print(f'Recognized as {target}');\n",
    "    else :\n",
    "        print('not known');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    old_model = pickle.load(open(\"model_livenes.pkl\", 'rb'))\n",
    "    clfmodel = old_model[\"classifier\"]\n",
    "    targets = old_model[\"targets\"]\n",
    "    embeddings = old_model[\"embeddings\"]\n",
    "    target = np.unique(targets)\n",
    "    embedding = webcapture()\n",
    "    example_prediction = clfmodel.predict(embedding[0])\n",
    "    print(target)\n",
    "    print(clfmodel.decision_function(embedding[0]))\n",
    "    for i in range(len(target)):\n",
    "        print(targets[i*10])\n",
    "        avg = 0\n",
    "        for j in range(i*10,(i*10)+10):\n",
    "            avg += cosine_similarity([embeddings[j]], embedding[0])\n",
    "        avg = avg/10\n",
    "        print(\"avg\",avg)\n",
    "    if len(target)  >2 :\n",
    "        probablity = (1/(1+np.exp(-list(clfmodel.decision_function(embedding[0])[0])[np.argmax(clfmodel.decision_function(embedding[0]))])))\n",
    "        print( \"confidence\",list(clfmodel.decision_function(embedding[0])[0])[np.argmax(clfmodel.decision_function(embedding[0]))])\n",
    "        print(\"probability\",probablity)\n",
    "        if abs(list(clfmodel.decision_function(embedding[0])[0])[np.argmax(clfmodel.decision_function(embedding[0]))]) > 0.50  :\n",
    "            print(f'Recognized as {target[example_prediction[0]]}');\n",
    "        else :\n",
    "            print('not known');\n",
    "    else:\n",
    "        print(abs(clfmodel.decision_function(embedding[0])))\n",
    "        print(abs(clfmodel.decision_function(embedding[0])) > 0.50)\n",
    "        if abs(clfmodel.decision_function(embedding[0])) > 0.50  :\n",
    "            print(f'Recognized as {target[example_prediction[0]]}');\n",
    "        else :\n",
    "            print('not known');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "press 1 for enter face in database\n",
      "press 2 for see magic\n",
      "press 3 for exit\n",
      "2\n",
      "fake 0.93117964\n",
      "fake face\n",
      "real 0.89629084\n",
      "['het' 'kumar']\n",
      "[0.87802659]\n",
      "kumar\n",
      "avg [[0.89001286]]\n",
      "het\n",
      "avg [[0.48434168]]\n",
      "[0.87802659]\n",
      "[ True]\n",
      "Recognized as kumar\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print(\"press 1 for enter face in database\")\n",
    "    print(\"press 2 for see magic\")\n",
    "    print(\"press 3 for exit\")\n",
    "    choice = int(input())\n",
    "    if choice == 1:\n",
    "        name = input(\"enter name of person\")\n",
    "        if os.path.exists('model_livenes.pkl'):\n",
    "            old_model = pickle.load(open(\"model_livenes.pkl\", 'rb'))\n",
    "            target = old_model[\"targets\"]\n",
    "            embeddings = old_model[\"embeddings\"]\n",
    "            print(embeddings)\n",
    "            if name.strip() in target:\n",
    "                print(\"class is already present\")\n",
    "            else:\n",
    "                embedded = enter_face()\n",
    "                new_embedded =[]\n",
    "                for i in embedded:\n",
    "                    new_embedded.append(i[0][0])\n",
    "                new_embedded = np.array(new_embedded)\n",
    "                embeddings = np.concatenate((embeddings, new_embedded), axis=0)\n",
    "                for i in range(0,10):\n",
    "                    target.append(name)\n",
    "                train(embeddings,target)\n",
    "        else:\n",
    "            target= []\n",
    "            embeddings = enter_face()\n",
    "            embedded =[]\n",
    "            for i in embeddings:\n",
    "                embedded.append(i[0][0])\n",
    "            embedded = np.array(embedded)\n",
    "            for i in range(0,10):\n",
    "                    target.append(name)\n",
    "            trainfirst(embedded,target)\n",
    "    elif choice == 2:\n",
    "        if os.path.exists('model_livenes.pkl'):\n",
    "            old_model = pickle.load(open(\"model_livenes.pkl\", 'rb'))\n",
    "            target = np.unique(old_model[\"targets\"])\n",
    "            if len(target) > 1:\n",
    "                predict()\n",
    "            else : \n",
    "                predictfisrt()\n",
    "        else:\n",
    "            print(\"first do training\")\n",
    "        break\n",
    "    else :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
